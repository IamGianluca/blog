[
  {
    "objectID": "posts/2018-03-21-entropy.html",
    "href": "posts/2018-03-21-entropy.html",
    "title": "A brief introduction about Entropy",
    "section": "",
    "text": "Information Theory is a cornerstone of Machine Learning, yet most Data Science practitioners haven’t been formally trained on it. This blog post is meant to give a brief introduction about entropy, a foundamental measure of uncertainty, which is used in many popular Machine Learning algorithms.\n\nInformation theory studies the quantification, storage, and communication of information. ― cit. Wikipedia\n\nEntropy is a measure of randomness or, in other words, unpredictability. The higher the entropy, the more unpredictable an outcome is. This also represents the minimum expected code length necessary to encode samples of the random variable. Intuitively, the lower the entropy, the easier is to encode a random variable.\nSome popular Machine Learning algorithms ― e.g. Decision Tree, Random Forest, Gradient Boosting, XGBoost ― use entropy to decide when to split a leaf into two leaves.\nLet’s look at how entropy works using a very simple example. Let’s say we are playing a game which involves extracting marbles from an urn. Marbles can be only of two colors, either red or blue. The proportion of red and blue marbles is 70%-30%. How can we measure the uncertainty of this game? Entropy, can come to our rescue.\nEntropy, usually represented with the letter $ H $, is mathematically defined as:\n\\[\n\\begin{align}\n    H(X) &= \\sum_{i=1}^N P(x_i) \\log P\\left(\\frac{1}{x_i}\\right) \\\\\n    &= - \\sum_{i=1}^N P(x_i) \\log P(x_i)\n\\end{align}\n\\]\nIn our example, this would be:\n\\[\n\\begin{align}\n    H(X) &= - \\sum_{i=1}^{2} P(x_i) \\log P(x_i) \\\\\n    &= - P(x_i=blue) \\log P(x_i=blue) - P(x_i=red) \\log P(x_i=red) \\\\\n    &= - .30 \\log 0.30 - .70 \\log 0.70 \\\\\n    &= .610864\n\\end{align}    \n\\]\nIf you find it easier to read code than maths, we could define the entropy in Python with this simple function.\n\nimport numpy as np\n\ndef entropy(p):\n    \"\"\"Measure of randomness in Information Theory.\n\n    Args:\n        p (iterable): The probability of success.\n\n    Returns:\n        (float) The information entropy.\n    \"\"\"\n    return - np.sum([p_i * np.log(p_i) for p_i in p])\n\nThen, we could open a Python interpreter and execute the following commands to verify the results.\n\np = [.30, .70]\nentropy(p)\n\n0.6108643020548935\n\n\nWe haven’t yet mentioned the unit of measure of entropy, the “bit” (alternatively called “shannon”). The unit of measure of the entropy shouldn’t be confused with the binary digit.\n\nConfusion often arises because the words bit and binary digit are used interchangeably. But, within information theory, a bit and a binary digit are fundamentally different types of entities. A binary digit is a number that can adopt one of two possible values (0 or 1), whereas a bit is the maximum amount of information that can be conveyed by a binary digit. By analogy, a binary digit is like a container, whereas information is the amount of matter in the container. ― cit. Wikipedia\n\nIt should also be noted that, when $ P(x_i) = 0 $ for some $ i $, the value of the corresponding summand $ 0 (0) $ is taken to be $ 0 $.\nIn the next blog post I’ll show some applications of entropy in Machine Learning and Bayesian inference."
  },
  {
    "objectID": "posts/2021-05-28-how-to-start-career-in-data-science.html",
    "href": "posts/2021-05-28-how-to-start-career-in-data-science.html",
    "title": "How to start a career in Data Science",
    "section": "",
    "text": "Intro\nI’ve been asked this question many times by young practitioners and recent graduates. “What advice would you give to someone starting a career in Data Science?”.\n\n\nFall in love with the process\nFirst of all, make sure you have a true passion for Machine Learning. Like in many things, you need to fall in love with the process to ultimately be successful at something. Knowledge and expertise are built day after day and will eventually compound.\nYou need to be curious and have a genuine interest in understanding how things truly work ― you need to embrace First Principles Thinking.\n\n\nTake one great online course, then start competing in Kaggle\nIf you are not sure if Data Science is really something you love, take a semester to complete an excellent online course like fast.ai and work on one or two Kaggle competitions. This should give you first-hand experience of what the job is all about, although not a complete one.\nfast.ai’s “Practical Deep Learning for Coders” and “Deep Learning from the Foundations” are excellent courses. They strongly emphasize the practical aspect and teach you good practice in building knowledge and being effective.\n\n\n\nFig 1: fast.ai is a non-profit research group focused on deep learning and artificial intelligence.\n\n\nAfter that, it’s time to get your hands dirty and join Kaggle. Kaggle is a large community of Data Science practitioners. The platform organizes Machine Learning competitions, ranging from Computer Vision to Reinforcement Learning.\n\n\n\nFig 2: Kaggle is the world’s largest data science community with powerful tools and resources to help you achieve your data science goals.\n\n\nMy advice is to not get too distracted by the Public Leaderboard. What you’re interested in is building knowledge. Try to make little progress every day. It’s a long game, and you are here to learn.\n\n\nPractice over theory\nOne of the biggest mistakes I’ve seen many beginners make is to spend a disproportionate amount of time studying the theory before beginning to work on their first non-trivial project. This is the wrong way to go about it. The theory is undoubtedly essential, but practice solidifies understanding and makes you ultimately able to build things. This doesn’t mean you shouldn’t spend time learning the theory. Theory and practice should complement each other.\nHow can you find the right balance between theory and practice? Use your curiosity and First Principle Thinking. Focus on building knowledge. If you don’t understand how something works, don’t be discouraged. Write some code ― see the excellent keynote from John Rauser at Strata + Hadoop 2014 ― or search the internet. Learn as you need and make sure that every new concept sits on a mental map of the space.\n\n\nCode\n%%HTML\n&lt;div align=\"center\"&gt;\n    &lt;iframe width=\"560\" height=\"315\"\n    src=\"https://www.youtube.com/embed/5Dnw46eC-0o\"\n    &lt;/iframe&gt;\n&lt;/div&gt;\n\n\n\n    \n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"make-your-project-fantastic\" class=\"level1\"&gt;\n&lt;h1&gt;Make your project fantastic&lt;/h1&gt;\n&lt;p&gt;To conclude this post, I want to share some advice from &lt;a href=\"https://twitter.com/jeremyphoward\"&gt;Jeremy Howard&lt;/a&gt;:&lt;/p&gt;\n&lt;blockquote&gt;\n&lt;p&gt;Pick one project. Do it really well. Make it fantastic.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;p&gt;Work on one project at a time, and make sure you’re proud of your work. Leverage everything you have learned so far, refactor it, document it well, and finally share it.&lt;/p&gt;\n&lt;p&gt;Every one of these projects will be part of your professional portfolio. Make sure your portfolio showcases how great you are!&lt;/p&gt;\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;iamgianluca&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;iamgianluca&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\"&gt;About&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/about.html\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:https://github.com/iamgianluca\"&gt;https://github.com/iamgianluca&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:https://twitter.com/HeyIamGianluca\"&gt;https://twitter.com/HeyIamGianluca&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;iamgianluca - How to start a career in Data Science&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;iamgianluca - How to start a career in Data Science&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;iamgianluca - How to start a career in Data Science&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;iamgianluca&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const icon = \"\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn) {\n    const config = {\n      allowHTML: true,\n      content: contentFn,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start'\n    };\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/2023-04-17-chinchilla.html",
    "href": "posts/2023-04-17-chinchilla.html",
    "title": "Training Compute-Optimal LLMs",
    "section": "",
    "text": "In a paper published in 2022, researchers from DeepMind showed how we can extrapolate the ideal model size (N) and pre-training dataset size (D) to achieve thelowest possible validation loss given a predefined compute budget."
  },
  {
    "objectID": "posts/2023-04-17-chinchilla.html#whats-new",
    "href": "posts/2023-04-17-chinchilla.html#whats-new",
    "title": "Training Compute-Optimal LLMs",
    "section": "",
    "text": "In a paper published in 2022, researchers from DeepMind showed how we can extrapolate the ideal model size (N) and pre-training dataset size (D) to achieve thelowest possible validation loss given a predefined compute budget."
  },
  {
    "objectID": "posts/2023-04-17-chinchilla.html#how-does-it-works",
    "href": "posts/2023-04-17-chinchilla.html#how-does-it-works",
    "title": "Training Compute-Optimal LLMs",
    "section": "How does it works?",
    "text": "How does it works?\nThe team at DeepMind did run over 400 experiments with models ranging from 0.5B to 17B parameters and different dataset sizes. Critically, they chose these quantities while keeping fixed computing budgets, in order to later fit three models to estimate the optimal values for N and D to minimize the validation loss. The team used three approaches to estimating the optimal value for those quantities. All three approaches converged to very similar solutions, where doubling the size of the model should require doubling also the size of the training dataset.\n\nTo prove the validity of their findings, they trained a new LLM, named Chinchilla (70B parameters, 1.4T tokens), which was able to outperform much larger models like GPT-3 (175B parameters, 300B tokens) and Gopher (280B parameters, 300B tokens) in a series of benchmarks."
  },
  {
    "objectID": "posts/2023-04-17-chinchilla.html#why-it-matters",
    "href": "posts/2023-04-17-chinchilla.html#why-it-matters",
    "title": "Training Compute-Optimal LLMs",
    "section": "Why it matters?",
    "text": "Why it matters?\nThis work shows how LLMs trained in the past few years are not compute optimal, and could have achieved better results by selecting a smaller model size and much large pre-training dataset size. This is a significant results because it shows that much smaller models, that are cheaper to train and use at inference time, can be competitive and even outperform much larger models trained on less data."
  },
  {
    "objectID": "posts/2023-04-17-chinchilla.html#what-do-we-think",
    "href": "posts/2023-04-17-chinchilla.html#what-do-we-think",
    "title": "Training Compute-Optimal LLMs",
    "section": "What do we think?",
    "text": "What do we think?\nCompute optimal models are not necessarily the best models. As shown in recent work from XXX, given a fixed model size, training a model with even more tokens than what suggested in this paper, can lead to an even better model, while suffering minimal computing overhead. That said, the scaling law published by DeepMind can give us a good starting point to select a smaller model and dataset size to iterate fast, before confidently scale the model and dataset size"
  },
  {
    "objectID": "posts/2018-02-26-welcome.html",
    "href": "posts/2018-02-26-welcome.html",
    "title": "Welcome to my blog",
    "section": "",
    "text": "Welcome to my blog!\nMy name is Gianluca — although my friends call me Luca!\nI’ve been passionate about Machine Learning since 2013, when I first came across it at my first job after college in a digital advertising company. After starting as a Campaign Analyst, I was lucky enough to join the Machine Learning team and got hooked in. Since then, I’ve been on a journey to learn more about AI and ML.\n\nThis is blog is meant to be a space for me to explain some interesting ML concepts and share some of my own research. I believe the best way of learning something is to teach it to someone else, and a blog is a good way to accomplish that.\nI hope you enjoy my writing and share your comments and feedback.\nBest,\nLuca"
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "",
    "text": "A recent post on Twitter made me realize many don’t notice the actual value Kaggle brings to the larger ML community and Kagglers.\nMost media attention focuses on Kaggle GrandMasters and the record-breaking prizes sometimes offered by companies sponsoring those Challenges. The publicity is good but does not give justice to the crucial value-adding contributions of Kaggle.\nBefore diving into why Kaggle is such a good platform, I want to highlight the value of open competitions ― like the ones organized by Kaggle."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#why-are-competitions-so-important",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#why-are-competitions-so-important",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "Why are competitions so important?",
    "text": "Why are competitions so important?\nThe recent acceleration of innovation in many ML tasks is primarily motivated by open competition and shared standards. If it weren’t for benchmarks like ImageNet, COCO, and WikiText, the progress in Computer Vision and NLP would have been much slower. Companies and research labs would have continued to invest in research, but we would not be in a state where new SOTA models are released almost weakly.\nThese open competitions are a positive-sum game for society. Companies and labs don’t need to reinvent the wheel each time. Instead, they can build on top of knowledge shared by others to make progress rapidly. This practice also has other significant impacts on society, thanks to reduced pollution and better affordable AI-driven products.\nI can see lots of similarities between the competitions organized by Kaggle and, for instance, the yearly ImageNet challenge."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#its-a-free-apprenticeship-not-unpaid-labor",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#its-a-free-apprenticeship-not-unpaid-labor",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "It’s a free apprenticeship, not unpaid labor",
    "text": "It’s a free apprenticeship, not unpaid labor\nIt is hard to deny the positive impact Kaggle had in building a global community of people passionate about ML. It is also hard to deny the number of people who had transitioned to a career in Data Science thanks to what they learned while competing at Kaggle.\nWhile competing with others, Kagglers are learning transferable skills. For instance, the first thing you learn in Kaggle is the value of a robust cross-validation strategy. This skill is critical in the real world. Similarly, after a few competitions, people organically learn how to be effective and good practices, motivated by being competitive with other contestants who have already learned such skills. These skills are hard to acquire in school, bootcamp, or by reading a book.\nIn this sense, Kaggle is a free apprenticeship led by the community."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#a-fantastic-resource-also-for-experienced-scientists",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#a-fantastic-resource-also-for-experienced-scientists",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "A fantastic resource also for experienced scientists",
    "text": "A fantastic resource also for experienced scientists\nThere are also enormous benefits for people that have already established a career in ML. By participating in Kaggle competitions, you can get exposure to ML tasks you don’t face at work and keep up with the SOTA. In addition, constant exposure to best practices and tools allows Kagglers to continuously acquire new skills and get ready for even bigger challenges in the future.\nFor every Kagglers, the beauty of the platform is not about the Private Leaderboard or the Globa Ranking. Those are just a tool to encourage people to go the extra mile. Kaggle is about learning.\nThe platform is also rewarding people for sharing good datasets, notebooks, and discussions. I would also argue that many users don’t care about the Leaderboard and Rankings in general. Those are just side effects, and people have real lives. In a sense, it’s like running or any other hobby. Not everyone trains to win the Boston Marathon or the Olympics. Most people run just because it’s a healthy habit."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#its-a-level-playing-field",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#its-a-level-playing-field",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "It’s a level playing field",
    "text": "It’s a level playing field\nNot everyone is lucky to work for a leading tech company, surrounded by dozens, if not hundreds, of the best minds in the field. Kaggle lets you learn from some of the very best talents in the industry, even if you live far from where the ML buzz happens. The only limit to your ability to grow is your motivation to try new things, read what others are sharing, and interacting with them.\nAt the end of each competition, every top-ranked team shares a description of their solution. Sometimes, top-ranked contestants even share the code used to generate their submission. This knowledge-sharing tradition contributes to creating a repository of knowledge everyone can use in future competitions and real-life challenges. Moreover, this knowledge is open to everyone and not hidden behind a paywall."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#new-sota-factory-and-a-true-benchmark-for-new-models-and-tools",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#new-sota-factory-and-a-true-benchmark-for-new-models-and-tools",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "New SOTA factory and a true benchmark for new models and tools",
    "text": "New SOTA factory and a true benchmark for new models and tools\nNowadays, to be competitive in a Kaggle challenge, it is not sufficient to use out-of-the-box solutions. Instead, competitors often merge ideas from recent research papers or even create entirely new methods later published.\nThe competition in every Kaggle competition is so fierce that recently released models and tools are immediately tested. This is a great way to gain an understanding of how generalizable are the results of research papers."
  },
  {
    "objectID": "posts/2021-06-19-the-benefits-of-kaggle.html#conclusion",
    "href": "posts/2021-06-19-the-benefits-of-kaggle.html#conclusion",
    "title": "Why Kaggle is the best way to sharpen your ML skills",
    "section": "Conclusion",
    "text": "Conclusion\nIn summary, Kaggle is a positive-sum game for society and an excellent investment of your time if you’re interested in becoming a better data scientist and stay up to date. I hope more people join this vibrant and welcoming community."
  },
  {
    "objectID": "posts/2018-10-28-1cycle.html",
    "href": "posts/2018-10-28-1cycle.html",
    "title": "The 1cycle policy",
    "section": "",
    "text": "In his most recent work, Leslie N. Smith gives extremely useful practical advice on how to train neural networks and tune the most important hyper-parameters. In his experiments, Smith was able to improve the current State Of The Art (SOTA) results on a number of datasets and network combinations, including the popular CIFAR-10, CIFAR-100, MNIST, and ImageNet.\nSmith argues that Learning Rate (LR), Momentum, batch size, and weight decay should be tuned synchronously to find the best configuration that minizines the validation loss and maximize validation accuracy. Such intuitive remark has however been elusive for many researchers in the recent past due to the computational cost associated with such strategies. An extensive grid search across a 4-dimensional hyper-parameters space would, in fact, be extremely expensive ― especially for the average user who doesn’t have at his disposal a cluster of GPUs for running experiments.\nLeslie Smith goal is therefore to both shade a light on the intrinsic dependencies between such hyper-parameters and presents a good heuristic to rapidly identify the best combination. In addition to that, Smith also gives easy to follow rules of thumbs regarding good starting hyper-parameters to use when approaching a new dataset or architecture, and hints at how to improve on the initial configuration. In this paper, Smith also introduces what he calls the 1cycle policy, a strategy to train neural networks which shows super-convergence capabilities in many datasets if hyper-parameters are correctly chosen.\n\nUnderfitting and Overfitting\nSmith points out how, to minimize the prediction error, we need to identify the sweet spot between underfitting and overfitting.\n\n\n\nA chart showing the relationship between underfitting and overfitting\n\n\nHe argues that hyper-parameter configurations which more rapidly reduce the validation loss in the first few epochs and then plateau are generally best, since they:\n\nEmpirically reach lower validation loss\nDramatically reduce computing time ― that can, therefore, be allocated to experiment other things\n\nSmith stresses how large Learning Rate values are desirable since they reduce underfitting and help to regularize the training. On other hand, Smith reminds the reader that extremely high values of Learning Rate can cause the training to diverge. To quickly identify reasonable minimum and maximum boundary values for the Learning Rates with only a few epochs, Smith suggests to use the “LR range test”, which he proposed in an earlier paper.\n\n\nThe 1cycle policy\nSuch a policy requires the coordinated change of Learning Rate and Momentum during training time. During the course of over 1,000 experiment, Smith noticed how a strategy of one cycle length wherein the first half we increase the LR while decrease Momentum, and then revert the trends in the second half of the cycle, seems to perform particularly well.\n\n\n\nA chart showing the learning rate and momentum schedule in the 1cycle policy\n\n\nIn Smith experiments, such policy outperforms in terms of validation score any other previously known training policy, and achieves optimal results in a fraction of the necessary epochs.\n\n\nBatch size, weight decay, and dropout\nSmall batch sizes, weight decay, and dropout are other popular techniques to regularize neural networks. Smith argues that these regularization techniques should be reduced in favor of using larger learning rates. Larger learning rates, in fact, provide as good regularization properties and, additionally, allow convergence in a shorter number of iterations.\nSmith suggested to use the largest batch size allowed by our server and to try a few different combinations of weight decay and dropout while comparing the results using the “LR range test”.\n\n\nGeneralization to different network architectures and dataset\nFinally, Smith explores how his recommendations generalize to different network architectures and datasets. Interestingly, he shows how his recommendations hold not just for shallow and residual networks but also in deep architectures like densenets, and hyper-densenets. He also shares the code he used to improve the results presented in numerous studies while also considerably reducing training time. This is extremely important to further validate the hypothesis that the 1cycle policy is the best currently known general strategy to optimize both shallow and deep networks architectures.\n\n\nConclusions\nThe recent work of Leslie N. Smith has been fundaments to democratize deep learning and achieving SOTA results on single and multi-GPU configurations. The “LR range test”, 1cycle policy, and the heuristics to tune Learning Rate, Momentum, batch size and weight decay presented in this paper are advancing what previously presented in the literature."
  },
  {
    "objectID": "posts/2021-05-29-effective-ml-dl-practitioner.html",
    "href": "posts/2021-05-29-effective-ml-dl-practitioner.html",
    "title": "How to become a more effective ML/DL practitioner",
    "section": "",
    "text": "Intro\nThis article is aimed to any practitioners that wants to become more effective. This is of course just my opinion, but I hope it will help many people struggling to make the next step in their career. I’ve shared many of this tips over the years and seen the powerful effect they had both on me and others.\nBefore we start, I’m expecting you to know very well the fundations of Machine Learning. This is necessary prerequisite for anyone working as a Data Scientist or Machine Learning engineer. After you have acquired a good understanding of the fundamentals, there are generally three things that will help you become more productive: * Have an effective development environment * Iterate faster * Continuous learning\nWe will see how these themes will come up repeatedly in this article.\n\n\nLearn how to code\nThe best investment in your productivity is to learn how to code properly. This means writing code that is reusable and modular. Don’t Repeat Yourself and Keep It Simple (Stupid) should be your guiding principles.\nRefactor your code often. Don’t procrastinate when you notice things that can be improved in the codebase. Cruft accumulates rapidly and in no time it will prevent you from iterate quickly. Refactoring is a critical component of the development lifecycle. Don’t neglect that.\nTry to be a good boyscout:\n\nAlways leave the campground cleaner than you found it.\n\nYour goal is to help your future self. You want to write code once, and reuse it in the future when the need arise. You don’t want to keep reimplementing the same function/class over and over again. You want to go out and accomplish bigger things.\nThere are two books I often recommend about good software development practices: * “Clean Code” by Robert C. Martin * “Refactoring” by Martin Fowler\nTwo key points here are consistency and discipline. You will get there!\n\n\nMaster your tools\nAs a Machine Learning practitioner, you will spend lots of your time working on a codebase, often connecting to a remote Linux server. There are some tools you must learn how to use well if you want to be effective. These include: * Git * The Linux command line * Docker\nOther tools I often recommend are: * tmux * powerline-shell * dvc\nI would also recommend you to use a dotfiles manager. There are many options out there. Choose one that works for you. Ideally, you would like to install your dotfiles in a new machine with just one command.\nI would also recommend you to choose some popular ML libraries and stick to them unless there is a clear advantage in switching to a new one. The software engineering and ML worlds are moving rapidly, and new tools are released seamingly weekly. Your goal is to be effective at build things, not learning how to master the lastest fancy tool.\n\nBecome one with your IDE\nMastering your IDE is essential. You will spend lots of time in it. You better be familiar with how to get the best out of it. Learn keybindings and keyboard shortcuts for those operations you do regularly. Learn how to rapidly navigate the codebase ― e.g., jump to definition, rename a symbol, etc. The faster you navigate a project, the quicker you can familiarize with it, implement new features, and fix bugs.\n\n\n\nFig 1: As a good craftsman, you must become one with your tools.\n\n\nAdditionally, every time you notice a repeated pattern, search how you could automate it. A few minutes per day saved will accumulate and leave you more time to think/work on more valuable problems.\nAvoid religious wars about IDEs. Choose what’s best for you and stick to it. I would also recommend you to stay away from people that are too opinionated about IDEs.\n\n\nBe comfortable with using a debugger\nBugs happen. Being able to interpret error messages and identify the root cause is critical to move fast. Read the error message. Follow the traceback to discover which line is triggering the error. Jump to that line in the codebase and analyze what is wrong. It is really that simple.\n\n\n\nIterate faster\nWhen starting a new project, you need to have a clear plan for making rapid sustainable progress.\n\nVisualize the data\nMany practitioners spend too little time familiarizing with the data. They simply load it in a DataLoader and pass it to a model. That might give you the false feeling of moving fast, but moving fast is worthless if you’re going in the wrong direction.\nSpend at least a few hours plotting distributions, looking at images, and inspecting outliers. That will give you a good understanding of what problems your model might face, and ultimately guide your progress.\nYou should not limit yourself to look at the data only at the beginning of a project. Use Error Analysis to understand what model improvement should lead the best return on investment.\n\n\nDefine ML pipeline skeleton\nStart by building a skeleton for the ML pipeline. Implement all the necessary steps ― e.g., download, unzip, create cross-validation folds, preprocess, train, predict, post-process ― without worrying too much about the overall solution. Keep things as simple as possible at this stage. Just make sure you have a pipeline you can rapidly improve on.\n\n\nCross-validation\nOnce the initial ML pipeline is ready, it’s time for you to focus on building a robust cross-validation strategy. Rachel Thomas wrote a brilliant blog article about it. I would recommend you to read it, if you haven’t already.\nRemember, cross-validation is crucial for making rapid progress. If you don’t have confidence in your validation strategy, you can’t trust the results of your experiments. Even worse, if you cross-validation strategy is flawed, you will have the false impression of making progress.\n\n\nChoose a good evaluation metric\nThis is another thing I’ve seen many get wrong. Focus on the ultimate goal. Play around with the evaluation metric and ensure you understand how it behaves ― don’t ignore the corner cases. Is the metric rewarding/penalizing models appropriately to your goal? It would be a waste of time to spend months improving on a metric to discover that it doesn’t align with the business goals.\n\n\nSample data\nMost of the time, there is no need to use all the available data to test some ideas. Make sure you’re working with enough data to have confidence in the results but little enough to be able to iterate quickly. The faster you iterate, the more ideas you can try, and the more progress you will make. Learning curves help identify a reasonable threshold for how much data you need.\nOf course, use all data available when training your final model(s). But for rapid development purposes, if you can get the same answers in half the time, that’s huge.\n\n\nStart with a simple baseline\nStart easy. Don’t jump immediately to the latest fancy model/architecture. Begin with a linear model or even simple frequencies. Once you have established a baseline, try to improve on that. Do it gradually, though.\nI’ve seen plenty of colleagues wasting months of work developing a fancy deep learning solution to discover that a simple linear model worked better because of a bug in their codebase.\n\n\nBe scientific\nToo often, I see less experienced practitioners trying things without having a real plan. Make sure you know how to diagnose if your model is underfitting or overfitting, and know how to address that. Formulate hypotheses and run experiments to validate them. If the experiment is not successful, make sure you understand why. That is how you build confidence and lasting knowledge. Don’t try random things in the hope of getting lucky. That is not effective.\n\n\n\nFig 2: The Scientific Method’s workflow.\n\n\nThere are massive non-linearities in input and output between top practitioners and the rest of the field. Top practitioners know what to do and why. Being “right” for the wrong reasons does not guarantee long-term success in this profession. You want to understand why something worked or did not. Be honest with yourself. That will pay off in the long term.\nOne great resource for learning how to be an effective ML practitioner is “Machine Learning Yearning” by Andrew Ng. The book is still under development, but you can get free access to the most recent draft."
  },
  {
    "objectID": "posts/2018-09-14-statistical-rethinking.html",
    "href": "posts/2018-09-14-statistical-rethinking.html",
    "title": "Statistical Rethinking",
    "section": "",
    "text": "statistical-rethinking-cover\n\n\nAfter reading the excellent reviews in Amazon, I decided to give it a go to the text-book Statistical Rethinking by Richard McElreath. Long story short, I can’t praise enough the author for this great book that I wish I have discovered long time ago, when I first started doing Bayesian data analysis.\nThe target reader for the book is a data analyst or data scientist with only a basic understanding on Bayesian inference. The author does a wonderful job of making sure to guide the reader from very simple concepts up to some intermediate level modeling techniques, like Multilevel Modeling. I’ve particularly appreciated the presence of plenty of excercises and the optional paragraphs where more advanced concepts are described ― without getting in the way of less experienced readers that want to get as much as possible from their first read of the material.\nThe book also contains lots of examples, using R and a companion open-source library named after the book. Even though I prefer much more the Python scientific eco-system for doing Data Science, and I haven’t touched R for quite a few years now, following the examples is very easy. The author also encapsuled all of the Stan models into it’s own wrapper library. I personally would have appreciated to see more Stan code, which I find quite easily interpretable, and would be anyway the language of choice for many readers after completing this book. Nonetheless, the companion library seems to be very compelling and will centainly bring you through all the examples in the book without much effort. For more advanced models though, Stan offers more flexibility.\nRegarding the content, I particularly appreciated the chapters about Information Theory and Multilevel models. These are probably the most advanced ones, but they are easy to follow and quite engaging also for more experienced users.\nThroughout the entire book, McElreath reiterate the importance of using counterfactual plots to understand the absolute effect of a feature on the target variable, and WAIC to compare alternative models. This is something I’ve particularly appreciated and I believe it should be promoted more often. I wish these kind of advices were given to me when I started my journey into Bayesian inference.\nTo summarize, Statistical Rethinking is a very enjoyable book, packed with important lessons for both beginner and intermediate practitioners who want to better understand how to do proper Bayesian data analysis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yet Another Blog about Machine Learning",
    "section": "",
    "text": "Training Compute-Optimal LLMs\n\n\n\n\n\n\n\narxiv\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nWhy Kaggle is the best way to sharpen your ML skills\n\n\n\n\n\n\n\nkaggle\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2021\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nHow to become a more effective ML/DL practitioner\n\n\n\n\n\n\n\ndeep learning\n\n\nmachine learning\n\n\nproductivity\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2021\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nHow to start a career in Data Science\n\n\n\n\n\n\n\ndeep learning\n\n\nmachine learning\n\n\nadvice\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2021\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nThe 1cycle policy\n\n\n\n\n\n\n\narxiv\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2018\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nStatistical Rethinking\n\n\n\n\n\n\n\nbooks\n\n\nstatistics\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2018\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nA brief introduction about Entropy\n\n\n\n\n\n\n\ninformation-theory\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2018\n\n\nGianluca Rossi\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to my blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2018\n\n\nGianluca Rossi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my ml blog!\nI’m Gianluca Rossi, but feel free to call me Luca.\nI currently work as the Director of Machine Learning at Ontra, leading a team of Machine Learning Engineers and Platform Engineers working at the cutting edge of NLP, LLMs, Information Retrieval, and intelligent systems for understanding legal documents. Our daily work involves everything from collecting data annotations to training sophisticated LLMs, and ensuring they operate flawlessly in a high-stakes production environment.\nBefore joining Ontra, I was one of the founding members of the ML team at Farfetch, where our challenges spanned from creating advanced product recommendation systems to engaging in the dynamic world of real-time bidding and predictive modeling.\nMy journey into Machine Learning began in 2013, at a small start-up called Struq, which was later incorporated into Quantcast. There, we developed a robust real-time bidding engine and a personalized recommendation system, both designed for high-speed, low-latency operation, processing over 16 PetaBytes of data every day.\nThrough my career, I’ve had the privilege of collaborating with amazing people from whom I’ve learned immensely. My passion for machine learning, deep learning, and software engineering is reflected in the various projects you can find on my GitHub profile, which I tackle in my free time.\nThis blog is where I share my knowledge on AI/ML topics, discussing both the theoretical underpinnings and practical applications, inspired by the philosophy that teaching is one of the best learning methods.\nI welcome you to engage with the content here, share your viewpoints, and enrich our discussions with your feedback."
  }
]